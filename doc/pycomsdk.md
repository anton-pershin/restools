# Research organizer pycomsdk
Whatever computational research you are doing, you will inevitably struggle with the same routines:
- simply organizing data produced by your code;
- backing up the same data;
- launching usually the same commands or scripts or their combinations on local and remote machines;
- gathering data from the remotes;
- collecting data for post-processing

Research organizer offers a straight-forward approach attacking all these issues by a single weapon. 

## Research data

First of all, we separate research data and codes used to produce the data. To store the research data, a simple hierarchy is introduced:
```
ROOT
  |
  ------ 2008-08-08_RESEARCH_1
  |             |
  |             ----------- 1_Task_1
  |             |
  |             ----------- 2_Task_2
  |             |
  |             ----------- 3_Task_3
  |
  ------ 2008-08-08_RESEARCH_2
               |
               ----------- 1_Task_1
               |
               ----------- 2_Task_2
               |
               ----------- 3_Task_3
```

There may be several `ROOT` with overlapping "research" catalogs and non-overlapping "tasks". These roots must be defined in `config_research.json` in the field `LOCAL_HOST.research_roots`.

Note that here we introduce two entities: "research" and "task". By research, we understand a collection of various tasks related to a subject which is relatively independent from other subjects within your scientific investigation. The division between different research is merely logical and made for your own good. By task, we understand a particular computation or, more correctly, a group of linked code runs. Note that tasks are enumerated (though there is no restriction on the integer step between task numbers). 

Research and task creation should be done using a management script `restools/manage.py`: see [docs](/doc/manage.md) for details.

## Remote host interaction

Since restools aims at processing data both locally and remotely, we need to have a replicated storage for research data on a given remote machine. We use SSH to transfer data between local and remote machines and run codes on remote machines.

The communication module is essentially a simplified filesystem and command line (it uses ssh in background when working with a remote machine).

TODO: describe Communication classes 

## Task launch: graph-based algorithms

By task, we understand 
* execution of an algorithm via shell and a set of instructions moving of data needed for this algorithm to be executed correctly
* all the output data generated by this algorithm 
Complex algorithms often consist of many steps performed by different internal/external programs. We found it useful to express such algorithms as graphs (`class Graph`) whose nodes (`class State`) denote the current state of the algorithm and edges (`class Edge`) denote particular functions/programs to be executed. Usually, an algorithm is implemented by creating a set of states (instances of `State`) and then connect them using method `State.connect_to()` and edges (instances of `Edge`). There is a collection of useful edges already implemented:
* `pycomsdk.edge.ExecutableProgramEdge` to run external program or a local or remote machine using a command-line arguments (done by classes in `pycomsdk.communication` classes)
* `pycomsdk.edge.QsubScriptEdge` to prepare SGE script for job scheduler
* `pycomsdk.edge.UploadOnRemoteEdge` to upload necessary files to the remote machine (done by classes in `pycomsdk.communication` classes)
* `pycomsdk.edge.DownloadFromRemoteEdge` to download necessary files from the remote machine (done by classes in `pycomsdk.communication` classes)
* `restools.standardised_programs.StandardisedProgramEdge` to run a `restools.standardised_programs.StandardisedProgram`
* and some others
It is also typical to reuse already implemented graphs (in this context, they are called subgraphs). It is easy to do if a graph corresponding some algorithm is implemented as a child class of `Graph` and also implement a static method `create_branch()`. In the constructor, the child class will construct a graph with task creation, but in `create_branch()` only task-free part of the algorithm will be implemented. We suggest to use this schema for all the algorithms implemented as graphs. Here is a useful template:
```python
class NewAlgorithmGraph(Graph):
    def __init__(self, ..., input_filename):
        def task_name_maker(d):
            task_name = task_prefix
            task_name += '_param1_{}'.format(d['param1'])
            task_name += '_param2_{}'.format(d['param2'])
            task_name += '_param3_{}'.format(len(d['param2']))
            return task_name
        task_start, task_end = CreateTaskGraph.create_branch(res, task_name_maker=task_name_maker)
        alg_init, alg_term = NewAlgorithmGraph.create_branch(...)
        dumping_edge = Edge(dummy_predicate, Func())
        task_end.connect_to(ti_init, edge=dumping_edge)
        dumping_edge.postprocess = make_dump(input_filename, omit=['res'], method='json')
        super().__init__(task_start, ti_term)

    @staticmethod
    def create_branch(..., relative_keys=(), keys_mapping={}, array_keys_mapping=None):
        s_init = State('READY', array_keys_mapping=array_keys_mapping)
        s_term = State('NEW_ALGORITHM_FINISHED')
        algorithm_edge = StandardisedProgramEdge(..., relative_keys=relative_keys, keys_mapping=keys_mapping)
        s_init.connect_to(s_term, edge=algorithm_edge)
        return s_init, s_term
```

TODO: describe iomapping and other details.

If we launch tasks on a remote machine, there will appear a (incomplete) replication of the tasks hierarchy on it. It is again created automatically. Moreover, we support a distributed storage on the local machine which can be useful if you are using an external hard drive to store your data permanently but still want to perform some tasks within your main filesystem. A distributed storage maintains a consistent state of the tasks within several research directories such that they can be distributed among them without any local duplicates.

TODO: describe taxonomy of classes